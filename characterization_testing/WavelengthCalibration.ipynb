{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3d852-3b99-451e-9a53-632d691235a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENTSDB_PYTHON_METRICS_TEST_MODE'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5b0a8-e5cc-473a-afb4-928f591f3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.resources\n",
    "from astropy.io import ascii\n",
    "from astropy.io import fits\n",
    "from banzai.calibrations import make_master_calibrations\n",
    "import requests\n",
    "from banzai_floyds import settings\n",
    "from banzai.dbs import get_instruments_at_site\n",
    "from banzai import dbs\n",
    "from banzai.utils.stage_utils import run_pipeline_stages\n",
    "from banzai.utils.fits_utils import download_from_s3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1012be-df25-4897-b461-9a19989ae61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('test_data', exist_ok=True)\n",
    "os.environ['DB_ADDRESS'] = 'sqlite:///test_data/test.db'\n",
    "settings.processed_path= os.path.join(os.getcwd(), 'test_data')\n",
    "settings.fpack=True\n",
    "settings.db_address = os.environ['DB_ADDRESS']\n",
    "settings.RAW_DATA_FRAME_URL = f'https://archive-api.lco.global/frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf6321-23f3-4523-82d7-d4e3c5884371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the context object.\n",
    "import banzai.main\n",
    "context = banzai.main.parse_args(settings, parse_system_args=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab4bee-2654-47c1-a746-e0de5616766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'banzai_floyds_create_db --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_site --site ogg --latitude 20.7069444444\t--longitude -156.258055556 --elevation 3065 --timezone -10 --db-address={os.environ[\"DB_ADDRESS\"]}');\n",
    "os.system(f'banzai_add_site --site coj --latitude -31.272932 --longitude 149.070648 --elevation 1116 --timezone 10 --db-address={os.environ[\"DB_ADDRESS\"]}');\n",
    "os.system(f'banzai_add_instrument --site ogg --camera en06 --name floyds01 --instrument-type 2m0-FLOYDS-SciCam --db-address={os.environ[\"DB_ADDRESS\"]} --nx 2079 --ny 512');\n",
    "os.system(f'banzai_add_instrument --site coj --camera en12 --name floyds02 --instrument-type 2m0-FLOYDS-SciCam --db-address={os.environ[\"DB_ADDRESS\"]} --nx 2079 --ny 512');\n",
    "\n",
    "ogg_instrument = get_instruments_at_site('ogg', os.environ[\"DB_ADDRESS\"])[0]\n",
    "\n",
    "os.system(f'banzai_floyds_add_order_location --order-id=1 --instrument-id={ogg_instrument.id} --xmin=0 --xmax=1550 --db-address={os.environ[\"DB_ADDRESS\"]}');\n",
    "os.system(f'banzai_floyds_add_order_location --order-id=2 --instrument-id={ogg_instrument.id} --xmin=500 --xmax=1835 --db-address={os.environ[\"DB_ADDRESS\"]}');\n",
    "\n",
    "coj_instrument = get_instruments_at_site('coj', os.environ[\"DB_ADDRESS\"])[0]\n",
    "os.system(f'banzai_floyds_add_order_location --order-id=1 --instrument-id={coj_instrument.id} --xmin=55 --xmax=1600 --db-address={os.environ[\"DB_ADDRESS\"]}');\n",
    "os.system(f'banzai_floyds_add_order_location --order-id=2 --instrument-id={coj_instrument.id} --xmin=615 --xmax=1920 --db-address={os.environ[\"DB_ADDRESS\"]}');\n",
    "\n",
    "os.system(f'banzai_floyds_add_order_location --order-id=1 --instrument-id={coj_instrument.id} --xmin=0 --xmax=1550 --good-after=\"2024-12-01T00:00:00.000000\" --db-address={os.environ[\"DB_ADDRESS\"]}');\n",
    "os.system(f'banzai_floyds_add_order_location --order-id=2 --instrument-id={coj_instrument.id} --xmin=615 --xmax=1965 --good-after=\"2024-12-01T00:00:00.000000\" --db-address={os.environ[\"DB_ADDRESS\"]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb8752-9328-4751-8cab-c2806ee60fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skyflat_files = ascii.read(os.path.join(importlib.resources.files('banzai_floyds.tests'), 'data/test_skyflat.dat'))\n",
    "for skyflat in skyflat_files:\n",
    "    skyflat_info = dict(skyflat)\n",
    "    skyflat_hdu = fits.open(download_from_s3(skyflat_info, context, is_raw_frame=True))\n",
    "\n",
    "    # Munge the data to be OBSTYPE SKYFLAT\n",
    "    skyflat_hdu['SCI'].header['OBSTYPE'] = 'SKYFLAT'\n",
    "    skyflat_name = skyflat_info[\"filename\"].replace(\"x00.fits\", \"f00.fits\")\n",
    "    filename = os.path.join('test_data', f'{skyflat_name}')\n",
    "    skyflat_hdu.writeto(filename, overwrite=True)\n",
    "    skyflat_hdu.close()\n",
    "    # Process the data\n",
    "    run_pipeline_stages([{'path': os.path.join(os.getcwd(), filename)}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b8dbb-279d-46e9-a7b0-ef65ddbfe5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ascii.read(os.path.join(importlib.resources.files('banzai_floyds.tests'), 'data/test_data.dat'))\n",
    "for row in test_data:\n",
    "    if 'a00.fits' in row['filename']:\n",
    "        run_pipeline_stages([{'filename': row['filename'], 'RLEVEL': 0, 'frameid': row['frameid']}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923fd08a-3881-4841-8eb0-bfb8cf1b6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0ddcb-9d44-41fd-82e7-7193a9cfa99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the old version of the data\n",
    "for frame in test_data:\n",
    "    if 'e00' in frame['filename']:\n",
    "        archive_url = f'https://archive-api.lco.global/frames/{frame[\"frameid\"]}'\n",
    "        raw_frame_info = requests.get(archive_url).json()\n",
    "        related_frame = raw_frame_info['related_frames'][0]\n",
    "        archive_tar_url = f'https://archive-api.lco.global/frames/{related_frame}'\n",
    "        frame_info = requests.get(archive_tar_url).json()\n",
    "        with open(os.path.join(os.getcwd(), 'test_data', frame_info['filename']), 'wb') as f:\n",
    "            f.write(requests.get(frame_info['url']).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5dc924-dc96-4e6f-b89d-d5c9c16ac037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9a292-7713-484e-acc7-6a3cae9216de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untar and extract the arc file deleting the rest\n",
    "for filename in glob('test_data/*.tar.gz'):\n",
    "    with tarfile.open(filename, 'r:gz') as f:\n",
    "        for file_to_extract in f.getnames():\n",
    "            if 'ttarc' == file_to_extract[:5]:\n",
    "                f.extract(file_to_extract, os.path.join(os.getcwd(), 'test_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3a870-c7cf-4fd9-aee7-108391e2bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits_header_to_wavelength(header):\n",
    "    crval = float(header['CRVAL1'])\n",
    "    crpix = float(header['CRPIX1'])\n",
    "    # Convert crpix to be zero indexed\n",
    "    crpix -= 1\n",
    "    if 'CDELT1' in header.keys():\n",
    "        cdelt = float(header['CDELT1'])\n",
    "    else:\n",
    "        cdelt = float(header['CD1_1'])\n",
    "    npix = float(header['NAXIS1'])\n",
    "    lam = np.arange(crval - cdelt * crpix ,\n",
    "                    crval + cdelt * (npix - crpix) - 1e-4,\n",
    "                    cdelt)\n",
    "    return lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c290d8-db6d-4653-bef8-5e3efc041da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from banzai_floyds.orders import orders_from_fits\n",
    "from banzai_floyds.wavelengths import WavelengthSolution\n",
    "from banzai_floyds.extract import extract\n",
    "from banzai_floyds.utils.binning_utils import bin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa73e87-edee-4b35-9827-537f49b802c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overplot the old arc on the new data blue and red\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=8, cols=1, x_title= u'Wavelength (\\u212B)', y_title='Normalized Flux')\n",
    "\n",
    "old_files = glob('test_data/ttarc_*.fits')\n",
    "old_files.sort()\n",
    "\n",
    "new_files = glob('test_data/*/*/*/processed/*a91*')\n",
    "request_numbers = {}\n",
    "for filename in new_files:\n",
    "    hdu = fits.open(filename)\n",
    "    request_numbers[hdu['SCI'].header['REQNUM']] = filename\n",
    "\n",
    "for i, filename in enumerate(old_files):\n",
    "    hdu = fits.open(filename)\n",
    "    iraf_wavelengths = fits_header_to_wavelength(hdu[0].header)\n",
    "    red_blue = os.path.basename(filename).split('_')[4]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=iraf_wavelengths, y=hdu[0].data[0, :]/np.max(hdu[0].data[0, :]), name='IRAF',\n",
    "                  line_color='coral', legendgroup=i+1),\n",
    "        row=i+1, col=1,\n",
    "    )\n",
    "    if red_blue == 'red':\n",
    "        text_x = 5500\n",
    "    else:\n",
    "        text_x = 3600\n",
    "    fig.add_annotation(x=text_x, y=0.8,\n",
    "            text=f'{hdu[0].header[\"SITEID\"]} {hdu[0].header[\"DAY-OBS\"]} {red_blue}',\n",
    "            showarrow=False,\n",
    "            yshift=10, row=i+1, col=1)\n",
    "    try:\n",
    "        new_filename = request_numbers[hdu[0].header['REQNUM']]\n",
    "        new_hdu = fits.open(new_filename)\n",
    "        orders = orders_from_fits(new_hdu['ORDER_COEFFS'].data, new_hdu['ORDER_COEFFS'].header, new_hdu['SCI'].data.shape)\n",
    "        wavelengths = WavelengthSolution.from_header(new_hdu['WAVELENGTHS'].header, orders)\n",
    "        binned_data = bin_data(new_hdu['SCI'].data, new_hdu['ERR'].data, wavelengths, orders)\n",
    "        binned_data['background'] = 0.0\n",
    "        binned_data['weights'] = 1.0\n",
    "        extracted_data = extract(binned_data)\n",
    "    \n",
    "        if red_blue == 'red':\n",
    "            order_to_plot = 1\n",
    "        else: \n",
    "            order_to_plot = 2\n",
    "        where_order = extracted_data['order'] == order_to_plot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=extracted_data['wavelength'][where_order], y=extracted_data['fluxraw'][where_order]/np.max(extracted_data['fluxraw'][where_order]), name='BANZAI-FLOYDS',\n",
    "                      line_color='steelblue', legendgroup=i+1),\n",
    "            row=i+1, col=1,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "fig.update_layout(height=2400, width=1200, title_text=\"Wavelength Calibration Comparison\", legend_tracegroupgap = 270,)\n",
    "fig.update_yaxes(title_text=\"Normalized Flux\", row=1, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a385fa5d-643a-490b-a87d-d4fdb6b40146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from banzai_floyds.arc_lines import arc_lines_table\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.modeling import models, fitting\n",
    "lines = arc_lines_table()\n",
    "from banzai_floyds.wavelengths import identify_peaks, refine_peak_centers\n",
    "\n",
    "def calculate_residuals(wavelengths, flux, flux_errors, lines):\n",
    "    residuals = []\n",
    "    residuals_wavelengths = []\n",
    "    peaks = np.array(identify_peaks(flux, flux_errors, 4, 10, snr_threshold=15.0))\n",
    "    for line in lines[lines['used']]:\n",
    "        if line['wavelength'] > np.max(wavelengths) or line['wavelength'] < np.min(wavelengths):\n",
    "            continue\n",
    "        closest_peak = peaks[np.argmin(np.abs(wavelengths[peaks] - line['wavelength']))]\n",
    "        closest_peak_wavelength = wavelengths[closest_peak]\n",
    "        if np.abs(closest_peak_wavelength - line['wavelength']) <= 20:\n",
    "            refined_peak = refine_peak_centers(flux, flux_errors, np.array([closest_peak]), 4)[0]\n",
    "            if not np.isfinite(refined_peak): \n",
    "                continue\n",
    "            if np.abs(refined_peak - closest_peak) > 5:\n",
    "                continue\n",
    "            refined_peak = np.interp(refined_peak, np.arange(len(wavelengths)), wavelengths)\n",
    "            residuals.append(refined_peak - line['wavelength'])\n",
    "            residuals_wavelengths.append(line['wavelength'])\n",
    "    return np.array(residuals_wavelengths), np.array(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0deaac4-95cb-4760-a997-43bb4fbf467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals for banzai-floyds and the iraf spectra\n",
    "fig = make_subplots(rows=8, cols=1, x_title= u'Wavelength (\\u212B)', y_title=u'Residuals (\\u212B)')\n",
    "\n",
    "old_files = glob('test_data/ttarc_*.fits')\n",
    "old_files.sort()\n",
    "\n",
    "new_files = glob('test_data/*/*/*/processed/*a91*')\n",
    "request_numbers = {}\n",
    "for filename in new_files:\n",
    "    hdu = fits.open(filename)\n",
    "    request_numbers[hdu['SCI'].header['REQNUM']] = filename\n",
    "\n",
    "for i, filename in enumerate(old_files):\n",
    "    hdu = fits.open(filename)\n",
    "    iraf_wavelengths = fits_header_to_wavelength(hdu[0].header)\n",
    "    red_blue = os.path.basename(filename).split('_')[4]\n",
    "\n",
    "    iraf_residuals_wavelengths, iraf_residuals = calculate_residuals(iraf_wavelengths, hdu[0].data[0, :], 0.01 * hdu[0].data[0, :], lines)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=iraf_residuals_wavelengths, y=iraf_residuals, name='IRAF',\n",
    "                  marker_color='coral', legendgroup=i+1, mode='markers'),\n",
    "        row=i+1, col=1,\n",
    "    )\n",
    "    if red_blue == 'red':\n",
    "        text_x = 5500\n",
    "    else:\n",
    "        text_x = 3600\n",
    "    iraf_rmse = np.sqrt(np.mean(iraf_residuals**2))\n",
    "\n",
    "    fig.add_annotation(x=0.01, y=0.95, xref='x domain', yref='y domain',\n",
    "            text=f'IRAF RMSE = {iraf_rmse:0.3f} ' + u'(\\u212B) <br>' + f' {hdu[0].header[\"SITEID\"]} {hdu[0].header[\"DAY-OBS\"]} {red_blue}',\n",
    "            showarrow=False, \n",
    "            yshift=10, row=i+1, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=2400, width=1200, title_text=\"Wavelength Calibration Comparison\", legend_tracegroupgap = 270,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d315f-bdf3-411b-8c49-0f9d7b7f5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals for banzai-floyds and the iraf spectra\n",
    "fig = make_subplots(rows=8, cols=1, x_title= u'Wavelength (\\u212B)', y_title=u'Residuals (\\u212B)')\n",
    "\n",
    "old_files = glob('test_data/ttarc_*.fits')\n",
    "old_files.sort()\n",
    "\n",
    "new_files = glob('test_data/*/*/*/processed/*a91*')\n",
    "request_numbers = {}\n",
    "for filename in new_files:\n",
    "    hdu = fits.open(filename)\n",
    "    request_numbers[hdu['SCI'].header['REQNUM']] = filename\n",
    "\n",
    "for i, filename in enumerate(old_files):\n",
    "    hdu = fits.open(filename)\n",
    "    iraf_wavelengths = fits_header_to_wavelength(hdu[0].header)\n",
    "    red_blue = os.path.basename(filename).split('_')[4]\n",
    "    if red_blue == 'red':\n",
    "        text_x = 5500\n",
    "    else:\n",
    "        text_x = 3600\n",
    "    iraf_rmse = np.sqrt(np.mean(iraf_residuals**2))\n",
    "\n",
    "    new_filename = request_numbers[hdu[0].header['REQNUM']]\n",
    "    new_hdu = fits.open(new_filename)\n",
    "    orders = orders_from_fits(new_hdu['ORDER_COEFFS'].data, new_hdu['ORDER_COEFFS'].header, new_hdu['SCI'].data.shape)\n",
    "    wavelengths = WavelengthSolution.from_header(new_hdu['WAVELENGTHS'].header, orders)\n",
    "    binned_data = bin_data(new_hdu['SCI'].data, new_hdu['ERR'].data, wavelengths, orders)\n",
    "    binned_data['background'] = 0.0\n",
    "    binned_data['weights'] = 1.0\n",
    "    extracted_data = extract(binned_data)\n",
    "\n",
    "    if red_blue == 'red':\n",
    "        order_to_plot = 1\n",
    "    else: \n",
    "        order_to_plot = 2\n",
    "    where_order = extracted_data['order'] == order_to_plot\n",
    "    residuals_wavelengths, residuals = calculate_residuals(extracted_data['wavelength'][where_order], extracted_data['flux'][where_order], extracted_data['fluxerror'][where_order], lines)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=residuals_wavelengths, y=residuals, name='BANZAI-FLOYDS',\n",
    "                  marker_color='steelblue', legendgroup=i+1, mode='markers'),\n",
    "        row=i+1, col=1,\n",
    "    )\n",
    "    rmse = np.sqrt(np.mean(residuals **2))\n",
    "    fig.add_annotation(x=text_x, y=1.0,\n",
    "            text=f'RMSE = {rmse} ' + u'(\\u212B)' + f' {hdu[0].header[\"SITEID\"]} {hdu[0].header[\"DAY-OBS\"]} {red_blue}',\n",
    "            showarrow=False,\n",
    "            yshift=10, row=i+1, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=2400, width=1200, title_text=\"Wavelength Calibration Comparison\", legend_tracegroupgap = 270,)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
