{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6dcad-d3c7-40c3-911f-1d8a7e28c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import ascii, fits\n",
    "import os\n",
    "import requests\n",
    "import importlib\n",
    "import io\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from skimage import measure\n",
    "from numpy.polynomial.legendre import Legendre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8db9b-e664-4f69-a2cd-44a6b8781f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_api = 'https://archive-api.lco.global/frames/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29181d14-72dd-4ace-a2f6-7aef2b573e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_frame(frame_id, filename, archive_api):\n",
    "    response = requests.get(archive_api + str(frame_id)).json()\n",
    "    buffer = io.BytesIO()\n",
    "    buffer.write(requests.get(response['url'], stream=True).content)\n",
    "    buffer.seek(0)\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f1698-ffd7-4aa6-b1cb-fce65d97ec21",
   "metadata": {},
   "source": [
    "Download the flat fields to get the location of the orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6e3d5-a3b9-4aa0-a748-e3a8dfa5cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "skyflat_files = ascii.read(os.path.join(importlib.resources.files('banzai_floyds.tests'), 'data/test_skyflat.dat'))\n",
    "for skyflat in skyflat_files:\n",
    "    skyflat_info = dict(skyflat)    \n",
    "    skyflat_hdu = fits.open(download_frame(skyflat_info['frameid'], skyflat_info['filename'], archive_api))\n",
    "\n",
    "    # Munge the data to be OBSTYPE SKYFLAT\n",
    "    skyflat_hdu['SCI'].header['OBSTYPE'] = 'SKYFLAT'\n",
    "    skyflat_name = skyflat_info[\"filename\"].replace(\"x00.fits\", \"f00.fits\")\n",
    "    filename = os.path.join('manual_reduction', f'{skyflat_name}')\n",
    "    skyflat_hdu.writeto(filename, overwrite=True)\n",
    "    skyflat_hdu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36932505-abfa-4fc6-bd8f-0a0065f84e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01e24d-c1a2-4791-8da8-e3d5cc012150",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogg_hdu = fits.open('manual_reduction/ogg2m001-en06-20190329-0018-f00.fits.fz')\n",
    "px.imshow(ogg_hdu['SCI'].data.astype(float), origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7991aa4-ac88-40b0-84f1-82dd0388d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = np.sum(sliding_window_view(ogg_hdu['SCI'].data, window_shape = 95, axis=0), axis=2)\n",
    "fig = px.imshow(convolved, origin='lower')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f1873-b7bf-4ead-a836-6ddaf3758479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a makeshift max filter in only the y-direction\n",
    "window_view_summed = sliding_window_view(convolved, window_shape=7, axis=0)\n",
    "max_filtered = np.max(window_view_summed, axis=2) == convolved[3:-3]\n",
    "\n",
    "# Detect the maxima and only filter out everything that isn't the main order centers\n",
    "ogg_center_labels = measure.label(max_filtered)\n",
    "ogg_center_properties = measure.regionprops(ogg_center_labels)\n",
    "for prop in ogg_center_properties:\n",
    "    if prop.area > 500:\n",
    "        edge = ogg_center_labels == prop.label\n",
    "        fig = px.imshow(edge, origin='lower')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44728b42-d9d8-477e-b02a-e5e136198f1b",
   "metadata": {},
   "source": [
    "Fit legendre polynomials to the edges, test to make sure that 99% of the pipeline region pixels fall between those two curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e26ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = {'coj': {1: {}, 2: {}}, 'ogg': {1: {}, 2: {}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afffbc0-9cf3-4412-b15a-bdff8e0b73e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2d, y2d = np.meshgrid(np.arange(ogg_hdu['SCI'].data.shape[1]), np.arange(ogg_hdu['SCI'].data.shape[0]))\n",
    "order_id = 1\n",
    "for prop in ogg_center_properties:\n",
    "    if prop.area > 500:\n",
    "        edge = np.zeros(ogg_hdu['SCI'].data.shape, dtype=bool)\n",
    "        # We have to convert back to original image coordinates\n",
    "        # We do this by taking the 95 pixel wide filter size and the 7 pixel wide max filter size\n",
    "        # and padding the filtered data by the half width of each\n",
    "        edge[95//2 + 7//2:-95//2 - 7//2 + 1] = ogg_center_labels == prop.label\n",
    "        # Fit a Legendre polynomial to the center of the order\n",
    "        x, y = x2d[edge], y2d[edge]\n",
    "        best_fit = Legendre.fit(x, y, 5)\n",
    "        coeffs = \",\".join(map(str, best_fit.coef))\n",
    "        domain = \",\".join(map(str, best_fit.domain))\n",
    "        range_str = \",\".join(map(str, best_fit.window))\n",
    "        print(f'Legendre(coef=[{coeffs}], domain=[{domain}], range=[{range_str}])')   \n",
    "        orders['ogg'][order_id]['coeffs'] = best_fit.coef\n",
    "        orders['ogg'][order_id]['domain'] = best_fit.domain\n",
    "        orders['ogg'][order_id]['window'] = best_fit.window\n",
    "        order_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8764532-0d5e-4260-a598-803a363f27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same procedure for COJ\n",
    "coj_hdu = fits.open('manual_reduction/coj2m002-en12-20220313-0002-f00.fits.fz')\n",
    "px.imshow(coj_hdu['SCI'].data.astype(float), origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67840839",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = np.sum(sliding_window_view(coj_hdu['SCI'].data, window_shape = 95, axis=0), axis=2)\n",
    "\n",
    "# Do a makeshift max filter in only the y-direction\n",
    "window_view_summed = sliding_window_view(convolved, window_shape=7, axis=0)\n",
    "max_filtered = np.max(window_view_summed, axis=2) == convolved[3:-3]\n",
    "\n",
    "# Detect the maxima and only filter out everything that isn't the main order centers\n",
    "coj_center_labels = measure.label(max_filtered)\n",
    "coj_center_properties = measure.regionprops(coj_center_labels)\n",
    "for prop in coj_center_properties:\n",
    "    if prop.area > 500:\n",
    "        edge = coj_center_labels == prop.label\n",
    "        fig = px.imshow(edge, origin='lower')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2d, y2d = np.meshgrid(np.arange(coj_hdu['SCI'].data.shape[1]), np.arange(coj_hdu['SCI'].data.shape[0]))\n",
    "order_id = 1\n",
    "for prop in coj_center_properties:\n",
    "    if prop.area > 500:\n",
    "        edge = np.zeros(coj_hdu['SCI'].data.shape, dtype=bool)\n",
    "        # We have to convert back to original image coordinates\n",
    "        # We do this by taking the 95 pixel wide filter size and the 7 pixel wide max filter size\n",
    "        # and padding the filtered data by the half width of each\n",
    "        edge[95//2 + 7//2:-95//2 - 7//2 + 1] = coj_center_labels == prop.label\n",
    "        # Fit a Legendre polynomial to the center of the order\n",
    "        x, y = x2d[edge], y2d[edge]\n",
    "        best_fit = Legendre.fit(x, y, 5)\n",
    "        coeffs = \",\".join(map(str, best_fit.coef))\n",
    "        domain = \",\".join(map(str, best_fit.domain))\n",
    "        range_str = \",\".join(map(str, best_fit.window))\n",
    "        print(f'Legendre(coef=[{coeffs}], domain=[{domain}], range=[{range_str}])') \n",
    "\n",
    "        orders['coj'][order_id]['coeffs'] = best_fit.coef\n",
    "        orders['coj'][order_id]['domain'] = best_fit.domain\n",
    "        orders['coj'][order_id]['window'] = best_fit.window\n",
    "        order_id += 1\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = ascii.read(os.path.join(importlib.resources.files('banzai_floyds.tests'), 'data/test_data.dat'))\n",
    "for frame in test_files:\n",
    "    frame_info = dict(frame)    \n",
    "    hdu = fits.open(download_frame(frame_info['frameid'], frame_info['filename'], archive_api))\n",
    "    hdu.writeto(os.path.join('manual_reduction', f'{frame_info[\"filename\"]}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e123f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from banzai_floyds.utils.order_utils import get_order_2d_region\n",
    "from banzai_floyds.arc_lines import used_lines\n",
    "from banzai_floyds.wavelengths import refine_peak_centers\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import os \n",
    "import json \n",
    "\n",
    "order_height = 95\n",
    "\n",
    "print([os.path.basename(filename) for filename in glob('manual_reduction/*a00.fits*')])\n",
    "\n",
    "for filename in glob('manual_reduction/*a00.fits*'):\n",
    "    hdu = fits.open(filename)\n",
    "    for order in [1, 2]:\n",
    "        x2d, y2d = np.meshgrid(np.arange(hdu['SCI'].data.shape[1]), np.arange(hdu['SCI'].data.shape[0]))\n",
    "        site = hdu['SCI'].header['SITEID']\n",
    "        order_center = Legendre(coef=orders[site][order]['coeffs'], domain=orders[site][order]['domain'],\n",
    "                                window=orders[site][order]['window'])\n",
    "        \n",
    "        order_mask = np.logical_and(x2d >= min(order_center.domain), x2d <= max(order_center.domain))\n",
    "        order_mask = np.logical_and(order_mask, y2d - order_center(x2d) >= -order_height // 2)\n",
    "        order_mask = np.logical_and(order_mask, y2d  - order_center(x2d) <=  order_height // 2)\n",
    "        order_region = get_order_2d_region(order_mask)\n",
    "        \n",
    "        starting_flux = hdu['SCI'].data[order_region][0]\n",
    "        pixel = np.arange(len(starting_flux))\n",
    "        fig = px.line(x=pixel, y=starting_flux)\n",
    "        fig.show()\n",
    "\n",
    "# Lines manually measured by Curtis 2024-09-09  (Same order as glob)\n",
    "\n",
    "catalog_lines = {\n",
    "    1: np.array([used_line['wavelength'] for used_line in used_lines[4:]]),\n",
    "    2: np.array([used_line['wavelength'] for used_line in used_lines[:5]])\n",
    "}\n",
    "\n",
    "\n",
    "starting_line_locations = {\n",
    "    'coj2m002-en12-20200813-0028-a00.fits.fz': \n",
    "        {1: np.array([295, 728, 758, 782, 816, 918, 1007, 1097, 1171, \n",
    "                1213, 1342, 1373, 1495, 1531, 1634]),\n",
    "         2: np.array([183, 411, 431, 591, 1229])\n",
    "         },\n",
    "    'coj2m002-en12-20200813-0015-a00.fits.fz': \n",
    "        {1: np.array([297, 730, 759, 782, 818, 921, 1010, 1099, 1172,\n",
    "                      1213, 1344, 1373, 1497, 1534, 1634]),\n",
    "         2: np.array([183, 413, 430, 594, 1231]),\n",
    "         },\n",
    "    'ogg2m001-en06-20200822-0028-a00.fits.fz':\n",
    "        {1: np.array([208, 644, 673, 695, 731, 836, 925, 1016, 1088, 1130,\n",
    "                      1261, 1291, 1415, 1451, 1551]),\n",
    "         2: np.array([201, 435, 456, 617, 1252]),\n",
    "         },\n",
    "    'ogg2m001-en06-20200822-0009-a00.fits.fz':\n",
    "        {1: np.array([208,  644, 672, 696, 731, 836, 925, 1016, 1089, 1131,\n",
    "             1262, 1291, 1414, 1450, 1551]),\n",
    "         2: np.array([201, 435, 456, 618, 1252])\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# Measured by eye by Curtis\n",
    "line_fwhms = {\n",
    "    'coj2m002-en12-20200813-0028-a00.fits.fz': {2: 596.2 - 589.5, 1: 1345.2 - 1340.2},\n",
    "    'coj2m002-en12-20200813-0015-a00.fits.fz': {2: 597.7 - 590.8, 1: 1346.5 - 1341.5},\n",
    "    'ogg2m001-en06-20200822-0028-a00.fits.fz': {2: 619.9 - 615.3, 1: 1263.4 - 1258.8},\n",
    "    'ogg2m001-en06-20200822-0009-a00.fits.fz': {2: 620.25 - 615.4, 1: 1263.5 - 1258.75}\n",
    "}\n",
    "poly_order = {\n",
    "    1: 5,\n",
    "    2: 2\n",
    "}\n",
    "\n",
    "wavelength_fits = {\n",
    "    'coj2m002-en12-20200813-0028-a00.fits.fz': {1: {'coef': [], 'domain': [], 'window': []}, 2: {'coef': [], 'domain': [], 'window': []}},\n",
    "    'coj2m002-en12-20200813-0015-a00.fits.fz':  {1: {'coef': [], 'domain': [], 'window': []}, 2: {'coef': [], 'domain': [], 'window': []}},\n",
    "    'ogg2m001-en06-20200822-0028-a00.fits.fz':  {1: {'coef': [], 'domain': [], 'window': []}, 2: {'coef': [], 'domain': [], 'window': []}},\n",
    "    'ogg2m001-en06-20200822-0009-a00.fits.fz':  {1: {'coef': [], 'domain': [], 'window': []}, 2: {'coef': [], 'domain': [], 'window': []}}\n",
    "}\n",
    "\n",
    "\n",
    "# and then fit row by row, a set of lines measured by hand for all 4 arc lamps\n",
    "for filename in starting_line_locations:\n",
    "    hdu = fits.open(os.path.join('manual_reduction', filename))\n",
    "    #then starting from the previous best fit, fit the next row\n",
    "    x2d, y2d = np.meshgrid(np.arange(hdu['SCI'].data.shape[1]), np.arange(hdu['SCI'].data.shape[0]))\n",
    "    site = hdu['SCI'].header['SITEID']\n",
    "    for order in [1, 2]:\n",
    "        figure = go.Figure()\n",
    "        order_center = Legendre(coef=orders[site][order]['coeffs'], domain=orders[site][order]['domain'],\n",
    "                                window=orders[site][order]['window'])\n",
    "        \n",
    "        order_mask = np.logical_and(x2d >= min(order_center.domain), x2d <= max(order_center.domain))\n",
    "        order_mask = np.logical_and(order_mask, y2d - order_center(x2d) >= -order_height // 2)\n",
    "        order_mask = np.logical_and(order_mask, y2d  - order_center(x2d) <=  order_height // 2)\n",
    "        order_region = get_order_2d_region(order_mask)\n",
    "\n",
    "        last_line_locations = starting_line_locations[filename][order]\n",
    "        n_orig_lines = len(starting_line_locations[filename][order])\n",
    "\n",
    "        # I have removed these lines in the current line list so no need to do it manually anymore\n",
    "        # Remove the 3rd line in the blue because it is often blended and not high enough s/n\n",
    "        #if order == 2:\n",
    "        #    last_line_locations = last_line_locations[np.arange(n_orig_lines) != 2]\n",
    "        #    this_catalog = catalog_lines[order][np.arange(n_orig_lines) != 2]\n",
    "        # In the red, remove the 4th line which is too low of s/n and too close to nearby lines\n",
    "        # I worry about the last line in the red, but it seems happier since it is isolated \n",
    "        #if order == 1:\n",
    "        #    last_line_locations = last_line_locations[np.arange(n_orig_lines) != 3]\n",
    "        #    this_catalog = catalog_lines[order][np.arange(n_orig_lines) != 3]\n",
    "\n",
    "        for j in range(order_height):\n",
    "            data = hdu['SCI'].data[order_region][j].astype(float)\n",
    "            gain = float(hdu['SCI'].header['GAIN'])\n",
    "            error = np.sqrt(hdu['SCI'].data[order_region][j].astype(float) * gain + hdu['SCI'].header['RDNOISE'] ** 2) / gain\n",
    "            data -= np.median(data)\n",
    "            measured_lines = refine_peak_centers(data, error, last_line_locations, line_fwhms[filename][order])\n",
    "            if j == 0:\n",
    "                pixel = np.arange(len(data))\n",
    "                fig = px.line(x=pixel, y=data)\n",
    "                for measured_line in measured_lines:\n",
    "                    data_height = data[int(np.round(measured_line))]\n",
    "                    fig.add_trace(go.Scatter(x=[measured_line, measured_line], y=[data_height * 1.1, data_height * 1.4], mode='lines', line=dict(color='salmon')))\n",
    "                fig.show()\n",
    "            best_fit = Legendre.fit(measured_lines, this_catalog, deg=poly_order[order],\n",
    "                                    domain=(0, len(data) - 1))\n",
    "            # save the Legendre polynomial for each row to include in the e2e test data\n",
    "            wavelength_fits[filename][order]['coef'].append(list(best_fit.coef))\n",
    "            wavelength_fits[filename][order]['domain'].append(list(orders[site][order]['domain']))\n",
    "            wavelength_fits[filename][order]['window'].append(list(best_fit.window)) \n",
    "            last_line_locations = measured_lines\n",
    "            # make a slider plot of each fit for each row to manually check each fit to make sure they look reasonable\n",
    "            residuals = best_fit(measured_lines) - this_catalog\n",
    "            figure.add_trace(go.Scatter(x=best_fit(measured_lines), y=residuals, mode='markers', name=f'{filename} Order {order} Row {j}', visible=(j == 0)))\n",
    "        # Create slider steps\n",
    "        steps = []\n",
    "        for i in range(order_height):\n",
    "            step = dict(\n",
    "                method=\"update\",\n",
    "                args=[{\"visible\": [k == i for k in range(order_height)]},\n",
    "                    {\"title\": f\"Fit for Row {i}\"}], \n",
    "            )\n",
    "            steps.append(step)\n",
    "\n",
    "        # Create slider\n",
    "        sliders = [dict(\n",
    "            active=0,\n",
    "            currentvalue={\"prefix\": \"Row: \"},\n",
    "            pad={\"t\": 50},\n",
    "            steps=steps\n",
    "        )]\n",
    "\n",
    "        # Update layout with slider\n",
    "        figure.update_layout(\n",
    "            sliders=sliders,\n",
    "            xaxis_title=\"Wavelength (Angstroms)\",\n",
    "            yaxis_title=\"Residuals (Angstroms)\"\n",
    "        )\n",
    "\n",
    "        figure.show()\n",
    "with open('../banzai_floyds/tests/data/wavelength_e2e_fits.dat', 'w') as f:\n",
    "    f.writelines(json.dumps(wavelength_fits, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f0501-423d-43dc-87f8-1ff869ff8739",
   "metadata": {},
   "source": [
    "TODO: check the 2d fft of the fringe image? I wonder if fitting phase parameters might actually work for the shifting to get rid of the lamp continuum\n",
    "\n",
    "TODO: Define a regression test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d872007-d554-495c-8522-122b660d491e",
   "metadata": {},
   "source": [
    "TODO: Use specreduce to extract each source, with quadratic background\n",
    "\n",
    "TODO: Regression test is that banzai extraction is within the noise of the manual extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a4e38-da28-4903-9041-7eb41f139a4b",
   "metadata": {},
   "source": [
    "TODO: Define regression tests for telluric correction and flux calibration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
